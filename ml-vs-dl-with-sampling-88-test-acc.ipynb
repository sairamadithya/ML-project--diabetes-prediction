{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom scipy import stats \nimport seaborn as sns \ndata= pd.read_csv('../input/diabetes-dataset/diabetes.csv')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:33:04.079435Z","iopub.execute_input":"2022-10-12T16:33:04.080571Z","iopub.status.idle":"2022-10-12T16:33:04.765635Z","shell.execute_reply.started":"2022-10-12T16:33:04.080419Z","shell.execute_reply":"2022-10-12T16:33:04.764707Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:33:07.718688Z","iopub.execute_input":"2022-10-12T16:33:07.719343Z","iopub.status.idle":"2022-10-12T16:33:07.745783Z","shell.execute_reply.started":"2022-10-12T16:33:07.719309Z","shell.execute_reply":"2022-10-12T16:33:07.744713Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 768 entries, 0 to 767\nData columns (total 9 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   Pregnancies               768 non-null    int64  \n 1   Glucose                   768 non-null    int64  \n 2   BloodPressure             768 non-null    int64  \n 3   SkinThickness             768 non-null    int64  \n 4   Insulin                   768 non-null    int64  \n 5   BMI                       768 non-null    float64\n 6   DiabetesPedigreeFunction  768 non-null    float64\n 7   Age                       768 non-null    int64  \n 8   Outcome                   768 non-null    int64  \ndtypes: float64(2), int64(7)\nmemory usage: 54.1 KB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"This data does not contain any null values. So we don't need to worry about filling/dropping values.","metadata":{}},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:33:10.273597Z","iopub.execute_input":"2022-10-12T16:33:10.274602Z","iopub.status.idle":"2022-10-12T16:33:10.282523Z","shell.execute_reply.started":"2022-10-12T16:33:10.274563Z","shell.execute_reply":"2022-10-12T16:33:10.281534Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"Pregnancies                 0\nGlucose                     0\nBloodPressure               0\nSkinThickness               0\nInsulin                     0\nBMI                         0\nDiabetesPedigreeFunction    0\nAge                         0\nOutcome                     0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"data.duplicated()\ndata=data.drop_duplicates()\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:33:53.439819Z","iopub.execute_input":"2022-10-12T16:33:53.440237Z","iopub.status.idle":"2022-10-12T16:33:53.463813Z","shell.execute_reply.started":"2022-10-12T16:33:53.440205Z","shell.execute_reply":"2022-10-12T16:33:53.462683Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n0            6      148             72             35        0  33.6   \n1            1       85             66             29        0  26.6   \n2            8      183             64              0        0  23.3   \n3            1       89             66             23       94  28.1   \n4            0      137             40             35      168  43.1   \n\n   DiabetesPedigreeFunction  Age  Outcome  \n0                     0.627   50        1  \n1                     0.351   31        0  \n2                     0.672   32        1  \n3                     0.167   21        0  \n4                     2.288   33        1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>148</td>\n      <td>72</td>\n      <td>35</td>\n      <td>0</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>183</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>137</td>\n      <td>40</td>\n      <td>35</td>\n      <td>168</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"The data doesn't contain any duplicate values also. Hence we need not worry about them.","metadata":{}},{"cell_type":"code","source":"data.describe()","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:33:56.358453Z","iopub.execute_input":"2022-10-12T16:33:56.359673Z","iopub.status.idle":"2022-10-12T16:33:56.395422Z","shell.execute_reply.started":"2022-10-12T16:33:56.359605Z","shell.execute_reply":"2022-10-12T16:33:56.394458Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\ncount   768.000000  768.000000     768.000000     768.000000  768.000000   \nmean      3.845052  120.894531      69.105469      20.536458   79.799479   \nstd       3.369578   31.972618      19.355807      15.952218  115.244002   \nmin       0.000000    0.000000       0.000000       0.000000    0.000000   \n25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n75%       6.000000  140.250000      80.000000      32.000000  127.250000   \nmax      17.000000  199.000000     122.000000      99.000000  846.000000   \n\n              BMI  DiabetesPedigreeFunction         Age     Outcome  \ncount  768.000000                768.000000  768.000000  768.000000  \nmean    31.992578                  0.471876   33.240885    0.348958  \nstd      7.884160                  0.331329   11.760232    0.476951  \nmin      0.000000                  0.078000   21.000000    0.000000  \n25%     27.300000                  0.243750   24.000000    0.000000  \n50%     32.000000                  0.372500   29.000000    0.000000  \n75%     36.600000                  0.626250   41.000000    1.000000  \nmax     67.100000                  2.420000   81.000000    1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.845052</td>\n      <td>120.894531</td>\n      <td>69.105469</td>\n      <td>20.536458</td>\n      <td>79.799479</td>\n      <td>31.992578</td>\n      <td>0.471876</td>\n      <td>33.240885</td>\n      <td>0.348958</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.369578</td>\n      <td>31.972618</td>\n      <td>19.355807</td>\n      <td>15.952218</td>\n      <td>115.244002</td>\n      <td>7.884160</td>\n      <td>0.331329</td>\n      <td>11.760232</td>\n      <td>0.476951</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.078000</td>\n      <td>21.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.000000</td>\n      <td>99.000000</td>\n      <td>62.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>27.300000</td>\n      <td>0.243750</td>\n      <td>24.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.000000</td>\n      <td>117.000000</td>\n      <td>72.000000</td>\n      <td>23.000000</td>\n      <td>30.500000</td>\n      <td>32.000000</td>\n      <td>0.372500</td>\n      <td>29.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.000000</td>\n      <td>140.250000</td>\n      <td>80.000000</td>\n      <td>32.000000</td>\n      <td>127.250000</td>\n      <td>36.600000</td>\n      <td>0.626250</td>\n      <td>41.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>17.000000</td>\n      <td>199.000000</td>\n      <td>122.000000</td>\n      <td>99.000000</td>\n      <td>846.000000</td>\n      <td>67.100000</td>\n      <td>2.420000</td>\n      <td>81.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"All bioparameters are in the range. Hence the data does not have observational/structural errors in them. Hence we need to worry about them.","metadata":{}},{"cell_type":"code","source":"for x in data.columns:\n    z=np.abs(stats.zscore(data[x]))\n    print(x+str(z))","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:33:59.046559Z","iopub.execute_input":"2022-10-12T16:33:59.046980Z","iopub.status.idle":"2022-10-12T16:33:59.094226Z","shell.execute_reply.started":"2022-10-12T16:33:59.046947Z","shell.execute_reply":"2022-10-12T16:33:59.092335Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Pregnancies0      0.639947\n1      0.844885\n2      1.233880\n3      0.844885\n4      1.141852\n         ...   \n763    1.827813\n764    0.547919\n765    0.342981\n766    0.844885\n767    0.844885\nName: Pregnancies, Length: 768, dtype: float64\nGlucose0      0.848324\n1      1.123396\n2      1.943724\n3      0.998208\n4      0.504055\n         ...   \n763    0.622642\n764    0.034598\n765    0.003301\n766    0.159787\n767    0.873019\nName: Glucose, Length: 768, dtype: float64\nBloodPressure0      0.149641\n1      0.160546\n2      0.263941\n3      0.160546\n4      1.504687\n         ...   \n763    0.356432\n764    0.046245\n765    0.149641\n766    0.470732\n767    0.046245\nName: BloodPressure, Length: 768, dtype: float64\nSkinThickness0      0.907270\n1      0.530902\n2      1.288212\n3      0.154533\n4      0.907270\n         ...   \n763    1.722735\n764    0.405445\n765    0.154533\n766    1.288212\n767    0.656358\nName: SkinThickness, Length: 768, dtype: float64\nInsulin0      0.692891\n1      0.692891\n2      0.692891\n3      0.123302\n4      0.765836\n         ...   \n763    0.870031\n764    0.692891\n765    0.279594\n766    0.692891\n767    0.692891\nName: Insulin, Length: 768, dtype: float64\nBMI0      0.204013\n1      0.684422\n2      1.103255\n3      0.494043\n4      1.409746\n         ...   \n763    0.115169\n764    0.610154\n765    0.735190\n766    0.240205\n767    0.202129\nName: BMI, Length: 768, dtype: float64\nDiabetesPedigreeFunction0      0.468492\n1      0.365061\n2      0.604397\n3      0.920763\n4      5.484909\n         ...   \n763    0.908682\n764    0.398282\n765    0.685193\n766    0.371101\n767    0.473785\nName: DiabetesPedigreeFunction, Length: 768, dtype: float64\nAge0      1.425995\n1      0.190672\n2      0.105584\n3      1.041549\n4      0.020496\n         ...   \n763    2.532136\n764    0.531023\n765    0.275760\n766    1.170732\n767    0.871374\nName: Age, Length: 768, dtype: float64\nOutcome0      1.365896\n1      0.732120\n2      1.365896\n3      0.732120\n4      1.365896\n         ...   \n763    0.732120\n764    0.732120\n765    0.732120\n766    1.365896\n767    0.732120\nName: Outcome, Length: 768, dtype: float64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"According to the z-score statistical parameter, the above datapoints are considered as outliers. But I dont think these are outliers and I consider that these data are essential for identfying diabetes condition.","metadata":{}},{"cell_type":"markdown","source":"The next step is feature scaling. I am doing a comparison of ML and DL for this dataset. For ML, i am considering SVM, which is a distance based algorithm. Hence normalization of data would be appropriate. On the other hand, for DL I am considering ANN, which is gradient descent based algorithm for which standardisation of data would be appropriate, since it can help in faster identification of local minima.","metadata":{}},{"cell_type":"code","source":"data_norm=data.copy()\nfor column in data.columns:\n    data_norm[column] = (data_norm[column] - data_norm[column].min()) / (data_norm[column].max() - data_norm[column].min()) \ndata_norm.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:34:04.465181Z","iopub.execute_input":"2022-10-12T16:34:04.465564Z","iopub.status.idle":"2022-10-12T16:34:04.491182Z","shell.execute_reply.started":"2022-10-12T16:34:04.465532Z","shell.execute_reply":"2022-10-12T16:34:04.490388Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n0     0.352941  0.743719       0.590164       0.353535  0.000000  0.500745   \n1     0.058824  0.427136       0.540984       0.292929  0.000000  0.396423   \n2     0.470588  0.919598       0.524590       0.000000  0.000000  0.347243   \n3     0.058824  0.447236       0.540984       0.232323  0.111111  0.418778   \n4     0.000000  0.688442       0.327869       0.353535  0.198582  0.642325   \n\n   DiabetesPedigreeFunction       Age  Outcome  \n0                  0.234415  0.483333      1.0  \n1                  0.116567  0.166667      0.0  \n2                  0.253629  0.183333      1.0  \n3                  0.038002  0.000000      0.0  \n4                  0.943638  0.200000      1.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.352941</td>\n      <td>0.743719</td>\n      <td>0.590164</td>\n      <td>0.353535</td>\n      <td>0.000000</td>\n      <td>0.500745</td>\n      <td>0.234415</td>\n      <td>0.483333</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.058824</td>\n      <td>0.427136</td>\n      <td>0.540984</td>\n      <td>0.292929</td>\n      <td>0.000000</td>\n      <td>0.396423</td>\n      <td>0.116567</td>\n      <td>0.166667</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.470588</td>\n      <td>0.919598</td>\n      <td>0.524590</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.347243</td>\n      <td>0.253629</td>\n      <td>0.183333</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.058824</td>\n      <td>0.447236</td>\n      <td>0.540984</td>\n      <td>0.232323</td>\n      <td>0.111111</td>\n      <td>0.418778</td>\n      <td>0.038002</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.688442</td>\n      <td>0.327869</td>\n      <td>0.353535</td>\n      <td>0.198582</td>\n      <td>0.642325</td>\n      <td>0.943638</td>\n      <td>0.200000</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"lis=['Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age','Pregnancies']\ndef standartization(x):\n    x_std = x.copy(deep=True)\n    for column in lis:\n        x_std[column] = (x_std[column] - x_std[column].mean()) / x_std[column].std() \n    return x_std\n\ndata= standartization(data)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:34:16.714932Z","iopub.execute_input":"2022-10-12T16:34:16.715536Z","iopub.status.idle":"2022-10-12T16:34:16.742023Z","shell.execute_reply.started":"2022-10-12T16:34:16.715504Z","shell.execute_reply":"2022-10-12T16:34:16.741029Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n0     0.639530  0.847771       0.149543       0.906679 -0.692439  0.203880   \n1    -0.844335 -1.122665      -0.160441       0.530556 -0.692439 -0.683976   \n2     1.233077  1.942458      -0.263769      -1.287373 -0.692439 -1.102537   \n3    -0.844335 -0.997558      -0.160441       0.154433  0.123221 -0.493721   \n4    -1.141108  0.503727      -1.503707       0.906679  0.765337  1.408828   \n\n   DiabetesPedigreeFunction       Age  Outcome  \n0                  0.468187  1.425067        1  \n1                 -0.364823 -0.190548        0  \n2                  0.604004 -0.105515        1  \n3                 -0.920163 -1.040871        0  \n4                  5.481337 -0.020483        1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.639530</td>\n      <td>0.847771</td>\n      <td>0.149543</td>\n      <td>0.906679</td>\n      <td>-0.692439</td>\n      <td>0.203880</td>\n      <td>0.468187</td>\n      <td>1.425067</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.844335</td>\n      <td>-1.122665</td>\n      <td>-0.160441</td>\n      <td>0.530556</td>\n      <td>-0.692439</td>\n      <td>-0.683976</td>\n      <td>-0.364823</td>\n      <td>-0.190548</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.233077</td>\n      <td>1.942458</td>\n      <td>-0.263769</td>\n      <td>-1.287373</td>\n      <td>-0.692439</td>\n      <td>-1.102537</td>\n      <td>0.604004</td>\n      <td>-0.105515</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.844335</td>\n      <td>-0.997558</td>\n      <td>-0.160441</td>\n      <td>0.154433</td>\n      <td>0.123221</td>\n      <td>-0.493721</td>\n      <td>-0.920163</td>\n      <td>-1.040871</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.141108</td>\n      <td>0.503727</td>\n      <td>-1.503707</td>\n      <td>0.906679</td>\n      <td>0.765337</td>\n      <td>1.408828</td>\n      <td>5.481337</td>\n      <td>-0.020483</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:34:25.319279Z","iopub.execute_input":"2022-10-12T16:34:25.319707Z","iopub.status.idle":"2022-10-12T16:34:25.334475Z","shell.execute_reply.started":"2022-10-12T16:34:25.319670Z","shell.execute_reply":"2022-10-12T16:34:25.333215Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 768 entries, 0 to 767\nData columns (total 9 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   Pregnancies               768 non-null    float64\n 1   Glucose                   768 non-null    float64\n 2   BloodPressure             768 non-null    float64\n 3   SkinThickness             768 non-null    float64\n 4   Insulin                   768 non-null    float64\n 5   BMI                       768 non-null    float64\n 6   DiabetesPedigreeFunction  768 non-null    float64\n 7   Age                       768 non-null    float64\n 8   Outcome                   768 non-null    int64  \ndtypes: float64(8), int64(1)\nmemory usage: 60.0 KB\n","output_type":"stream"}]},{"cell_type":"code","source":"data['Outcome'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:35:30.108680Z","iopub.execute_input":"2022-10-12T16:35:30.109148Z","iopub.status.idle":"2022-10-12T16:35:30.119089Z","shell.execute_reply.started":"2022-10-12T16:35:30.109110Z","shell.execute_reply":"2022-10-12T16:35:30.117889Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"0    500\n1    268\nName: Outcome, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"y=data['Outcome']\nx=data.drop(['Outcome'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:35:33.358733Z","iopub.execute_input":"2022-10-12T16:35:33.359772Z","iopub.status.idle":"2022-10-12T16:35:33.366001Z","shell.execute_reply.started":"2022-10-12T16:35:33.359734Z","shell.execute_reply":"2022-10-12T16:35:33.364772Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"yn=data_norm['Outcome']\nxn=data_norm.drop(['Outcome'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:35:34.258566Z","iopub.execute_input":"2022-10-12T16:35:34.259531Z","iopub.status.idle":"2022-10-12T16:35:34.267354Z","shell.execute_reply.started":"2022-10-12T16:35:34.259491Z","shell.execute_reply":"2022-10-12T16:35:34.266335Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"I am creating separate train and test sets for standardised and normalised data. the ones having n as suffix are normalised.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nxtrain,xtest,ytrain,ytest= train_test_split(x,y,test_size=0.15,stratify=y)\nprint(xtrain.shape)\nprint(xtest.shape)\nprint(ytrain.shape)\nprint(ytest.shape)","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:35:36.364145Z","iopub.execute_input":"2022-10-12T16:35:36.364949Z","iopub.status.idle":"2022-10-12T16:35:36.480658Z","shell.execute_reply.started":"2022-10-12T16:35:36.364911Z","shell.execute_reply":"2022-10-12T16:35:36.479385Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"(652, 8)\n(116, 8)\n(652,)\n(116,)\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nxntrain,xntest,yntrain,yntest= train_test_split(xn,yn,test_size=0.15,stratify=y)\nprint(xntrain.shape)\nprint(xntest.shape)\nprint(yntrain.shape)\nprint(yntest.shape)","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:35:37.454646Z","iopub.execute_input":"2022-10-12T16:35:37.455070Z","iopub.status.idle":"2022-10-12T16:35:37.465144Z","shell.execute_reply.started":"2022-10-12T16:35:37.455034Z","shell.execute_reply":"2022-10-12T16:35:37.463882Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"(652, 8)\n(116, 8)\n(652,)\n(116,)\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.svm import SVC\nsvm_model= SVC(kernel='rbf',gamma=8)\nsvm_model.fit(xntrain,yntrain)","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:35:43.006566Z","iopub.execute_input":"2022-10-12T16:35:43.007751Z","iopub.status.idle":"2022-10-12T16:35:43.092814Z","shell.execute_reply.started":"2022-10-12T16:35:43.007698Z","shell.execute_reply":"2022-10-12T16:35:43.091633Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"SVC(gamma=8)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\npredictions= svm_model.predict(xntrain)\npercentage=svm_model.score(xntrain,yntrain)\nres=confusion_matrix(yntrain,predictions)\nprint(\"Training confusion matrix\")\nprint(res)\npredictions= svm_model.predict(xntest)\npercentage=svm_model.score(xntest,yntest)\nres=confusion_matrix(yntest,predictions)\nprint(\"validation confusion matrix\")\nprint(res)\nprint(classification_report(ytest, predictions))\n# check the accuracy on the training set\nprint('training accuracy = '+str(svm_model.score(xntrain, yntrain)*100))\nprint('testing accuracy = '+str(svm_model.score(xntest, yntest)*100))","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:44:30.513644Z","iopub.execute_input":"2022-10-12T16:44:30.514248Z","iopub.status.idle":"2022-10-12T16:44:30.594251Z","shell.execute_reply.started":"2022-10-12T16:44:30.514216Z","shell.execute_reply":"2022-10-12T16:44:30.593090Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Training confusion matrix\n[[392  32]\n [ 75 153]]\nvalidation confusion matrix\n[[68  8]\n [15 25]]\n              precision    recall  f1-score   support\n\n           0       0.64      0.70      0.67        76\n           1       0.30      0.25      0.27        40\n\n    accuracy                           0.54       116\n   macro avg       0.47      0.47      0.47       116\nweighted avg       0.52      0.54      0.53       116\n\ntraining accuracy = 83.58895705521472\ntesting accuracy = 80.17241379310344\n","output_type":"stream"}]},{"cell_type":"markdown","source":"I trained the SVM without feature scaling and with standardisation. It produced test acc of 55% and 62% for no feature scaling and with standardisation. Hence normalisation is good for distance based algorithms like SVM.","metadata":{}},{"cell_type":"markdown","source":"For the DL part, I am considering ANN, comprising of 2 layers of 256 neurons as hidden layers. Considering more neurons and layers resulted in overfitting. Hence i limited with this hyperparameters. It was compiled using adam optimiser and crossentropy loss function.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\ndl_model = Sequential() \n\ndl_model.add(Dense(256,  activation = 'relu' ,input_shape=([8]))) #input layer\ndl_model.add(Dense(256,  activation = 'relu'))\ndl_model.add(Dense(1,activation = 'sigmoid'))\ndl_model.summary()\ndl_model.compile(optimizer = 'adam' , loss = 'binary_crossentropy' ,metrics = ['accuracy','Precision','Recall','AUC'])","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:41:17.495189Z","iopub.execute_input":"2022-10-12T16:41:17.495665Z","iopub.status.idle":"2022-10-12T16:41:17.540704Z","shell.execute_reply.started":"2022-10-12T16:41:17.495613Z","shell.execute_reply":"2022-10-12T16:41:17.539707Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_8 (Dense)              (None, 256)               2304      \n_________________________________________________________________\ndense_9 (Dense)              (None, 256)               65792     \n_________________________________________________________________\ndense_10 (Dense)             (None, 1)                 257       \n=================================================================\nTotal params: 68,353\nTrainable params: 68,353\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"num_epochs = 50\nhistory = dl_model.fit(xtrain ,\n                    ytrain ,\n                    epochs= num_epochs ,\n                    steps_per_epoch=200,\n                    validation_data=(xtest ,ytest))","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:41:33.274617Z","iopub.execute_input":"2022-10-12T16:41:33.275278Z","iopub.status.idle":"2022-10-12T16:41:55.437883Z","shell.execute_reply.started":"2022-10-12T16:41:33.275245Z","shell.execute_reply":"2022-10-12T16:41:55.436898Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Epoch 1/50\n200/200 [==============================] - 2s 5ms/step - loss: 0.5230 - accuracy: 0.7400 - precision: 0.6552 - recall: 0.5429 - auc: 0.7930 - val_loss: 0.5252 - val_accuracy: 0.7241 - val_precision: 0.6333 - val_recall: 0.4750 - val_auc: 0.7998\nEpoch 2/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7900 - precision: 0.7244 - recall: 0.6525 - auc: 0.8618 - val_loss: 0.5261 - val_accuracy: 0.7500 - val_precision: 0.6774 - val_recall: 0.5250 - val_auc: 0.8002\nEpoch 3/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7962 - precision: 0.7348 - recall: 0.6236 - auc: 0.8505 - val_loss: 0.5342 - val_accuracy: 0.7500 - val_precision: 0.7391 - val_recall: 0.4250 - val_auc: 0.8043\nEpoch 4/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7850 - precision: 0.7366 - recall: 0.6237 - auc: 0.8668 - val_loss: 0.4871 - val_accuracy: 0.7759 - val_precision: 0.7692 - val_recall: 0.5000 - val_auc: 0.8375\nEpoch 5/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7862 - precision: 0.7347 - recall: 0.6294 - auc: 0.8755 - val_loss: 0.5218 - val_accuracy: 0.7500 - val_precision: 0.6667 - val_recall: 0.5500 - val_auc: 0.8049\nEpoch 6/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.8062 - precision: 0.7457 - recall: 0.6431 - auc: 0.8796 - val_loss: 0.5308 - val_accuracy: 0.7759 - val_precision: 0.7500 - val_recall: 0.5250 - val_auc: 0.8145\nEpoch 7/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8062 - precision: 0.7569 - recall: 0.6748 - auc: 0.8813 - val_loss: 0.5285 - val_accuracy: 0.7586 - val_precision: 0.6875 - val_recall: 0.5500 - val_auc: 0.8051\nEpoch 8/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8225 - precision: 0.7842 - recall: 0.6774 - auc: 0.8978 - val_loss: 0.5826 - val_accuracy: 0.7414 - val_precision: 0.6136 - val_recall: 0.6750 - val_auc: 0.7785\nEpoch 9/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.3753 - accuracy: 0.8300 - precision: 0.7860 - recall: 0.6945 - auc: 0.8990 - val_loss: 0.5297 - val_accuracy: 0.7500 - val_precision: 0.7037 - val_recall: 0.4750 - val_auc: 0.8100\nEpoch 10/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8250 - precision: 0.7897 - recall: 0.6958 - auc: 0.9036 - val_loss: 0.5717 - val_accuracy: 0.7672 - val_precision: 0.6970 - val_recall: 0.5750 - val_auc: 0.7949\nEpoch 11/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8388 - precision: 0.7708 - recall: 0.7331 - auc: 0.9190 - val_loss: 0.6223 - val_accuracy: 0.7069 - val_precision: 0.6250 - val_recall: 0.3750 - val_auc: 0.7842\nEpoch 12/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.3488 - accuracy: 0.8388 - precision: 0.8168 - recall: 0.7254 - auc: 0.9164 - val_loss: 0.5157 - val_accuracy: 0.7586 - val_precision: 0.6364 - val_recall: 0.7000 - val_auc: 0.8155\nEpoch 13/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.3472 - accuracy: 0.8413 - precision: 0.7811 - recall: 0.7500 - auc: 0.9173 - val_loss: 0.5701 - val_accuracy: 0.7672 - val_precision: 0.7241 - val_recall: 0.5250 - val_auc: 0.7987\nEpoch 14/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.3027 - accuracy: 0.8662 - precision: 0.8366 - recall: 0.7679 - auc: 0.9374 - val_loss: 0.5587 - val_accuracy: 0.7328 - val_precision: 0.6286 - val_recall: 0.5500 - val_auc: 0.8062\nEpoch 15/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8550 - precision: 0.8171 - recall: 0.7390 - auc: 0.9319 - val_loss: 0.6598 - val_accuracy: 0.7328 - val_precision: 0.6452 - val_recall: 0.5000 - val_auc: 0.7681\nEpoch 16/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.2832 - accuracy: 0.8763 - precision: 0.8470 - recall: 0.8095 - auc: 0.9468 - val_loss: 0.6223 - val_accuracy: 0.7328 - val_precision: 0.6154 - val_recall: 0.6000 - val_auc: 0.7840\nEpoch 17/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.8850 - precision: 0.8533 - recall: 0.8036 - auc: 0.9529 - val_loss: 0.7118 - val_accuracy: 0.7586 - val_precision: 0.6579 - val_recall: 0.6250 - val_auc: 0.7646\nEpoch 18/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.2612 - accuracy: 0.8863 - precision: 0.8544 - recall: 0.8080 - auc: 0.9539 - val_loss: 0.6585 - val_accuracy: 0.7414 - val_precision: 0.6562 - val_recall: 0.5250 - val_auc: 0.7921\nEpoch 19/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.2524 - accuracy: 0.8925 - precision: 0.8676 - recall: 0.8252 - auc: 0.9590 - val_loss: 0.6960 - val_accuracy: 0.7155 - val_precision: 0.6061 - val_recall: 0.5000 - val_auc: 0.7702\nEpoch 20/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.9137 - precision: 0.8889 - recall: 0.8453 - auc: 0.9683 - val_loss: 0.7721 - val_accuracy: 0.7155 - val_precision: 0.5946 - val_recall: 0.5500 - val_auc: 0.7594\nEpoch 21/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.2199 - accuracy: 0.9087 - precision: 0.8885 - recall: 0.8615 - auc: 0.9712 - val_loss: 0.6763 - val_accuracy: 0.7328 - val_precision: 0.6216 - val_recall: 0.5750 - val_auc: 0.7836\nEpoch 22/50\n200/200 [==============================] - 1s 4ms/step - loss: 0.1973 - accuracy: 0.9162 - precision: 0.8868 - recall: 0.8640 - auc: 0.9750 - val_loss: 0.8134 - val_accuracy: 0.7328 - val_precision: 0.6154 - val_recall: 0.6000 - val_auc: 0.7735\nEpoch 23/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.9300 - precision: 0.9191 - recall: 0.8803 - auc: 0.9833 - val_loss: 0.8423 - val_accuracy: 0.7155 - val_precision: 0.6000 - val_recall: 0.5250 - val_auc: 0.7743\nEpoch 24/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9250 - precision: 0.9025 - recall: 0.8834 - auc: 0.9796 - val_loss: 0.7748 - val_accuracy: 0.7155 - val_precision: 0.5946 - val_recall: 0.5500 - val_auc: 0.7813\nEpoch 25/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.1473 - accuracy: 0.9488 - precision: 0.9466 - recall: 0.9018 - auc: 0.9889 - val_loss: 0.8895 - val_accuracy: 0.7069 - val_precision: 0.5714 - val_recall: 0.6000 - val_auc: 0.7660\nEpoch 26/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.1610 - accuracy: 0.9337 - precision: 0.9275 - recall: 0.8773 - auc: 0.9853 - val_loss: 0.9404 - val_accuracy: 0.7155 - val_precision: 0.5814 - val_recall: 0.6250 - val_auc: 0.7786\nEpoch 27/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.1313 - accuracy: 0.9550 - precision: 0.9446 - recall: 0.9242 - auc: 0.9911 - val_loss: 0.9119 - val_accuracy: 0.7328 - val_precision: 0.6216 - val_recall: 0.5750 - val_auc: 0.7525\nEpoch 28/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.1342 - accuracy: 0.9525 - precision: 0.9480 - recall: 0.9140 - auc: 0.9917 - val_loss: 0.8890 - val_accuracy: 0.7155 - val_precision: 0.6000 - val_recall: 0.5250 - val_auc: 0.7632\nEpoch 29/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.1213 - accuracy: 0.9613 - precision: 0.9509 - recall: 0.9410 - auc: 0.9920 - val_loss: 0.9536 - val_accuracy: 0.7414 - val_precision: 0.6389 - val_recall: 0.5750 - val_auc: 0.7666\nEpoch 30/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.1166 - accuracy: 0.9625 - precision: 0.9519 - recall: 0.9380 - auc: 0.9937 - val_loss: 1.0119 - val_accuracy: 0.7069 - val_precision: 0.5789 - val_recall: 0.5500 - val_auc: 0.7594\nEpoch 31/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.1001 - accuracy: 0.9675 - precision: 0.9600 - recall: 0.9462 - auc: 0.9961 - val_loss: 1.0404 - val_accuracy: 0.7328 - val_precision: 0.6286 - val_recall: 0.5500 - val_auc: 0.7531\nEpoch 32/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.0966 - accuracy: 0.9663 - precision: 0.9570 - recall: 0.9468 - auc: 0.9957 - val_loss: 1.0993 - val_accuracy: 0.7241 - val_precision: 0.6053 - val_recall: 0.5750 - val_auc: 0.7594\nEpoch 33/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.1141 - accuracy: 0.9638 - precision: 0.9474 - recall: 0.9507 - auc: 0.9919 - val_loss: 1.1323 - val_accuracy: 0.7155 - val_precision: 0.6000 - val_recall: 0.5250 - val_auc: 0.7362\nEpoch 34/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.0746 - accuracy: 0.9837 - precision: 0.9674 - recall: 0.9852 - auc: 0.9981 - val_loss: 1.2869 - val_accuracy: 0.6983 - val_precision: 0.5641 - val_recall: 0.5500 - val_auc: 0.7456\nEpoch 35/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.0695 - accuracy: 0.9837 - precision: 0.9791 - recall: 0.9757 - auc: 0.9983 - val_loss: 1.2556 - val_accuracy: 0.7069 - val_precision: 0.5789 - val_recall: 0.5500 - val_auc: 0.7566\nEpoch 36/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.0507 - accuracy: 0.9912 - precision: 0.9857 - recall: 0.9892 - auc: 0.9995 - val_loss: 1.3005 - val_accuracy: 0.7414 - val_precision: 0.6471 - val_recall: 0.5500 - val_auc: 0.7622\nEpoch 37/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.0590 - accuracy: 0.9837 - precision: 0.9758 - recall: 0.9792 - auc: 0.9989 - val_loss: 1.2358 - val_accuracy: 0.7069 - val_precision: 0.5750 - val_recall: 0.5750 - val_auc: 0.7520\nEpoch 38/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.0487 - accuracy: 0.9887 - precision: 0.9819 - recall: 0.9855 - auc: 0.9994 - val_loss: 1.3379 - val_accuracy: 0.7155 - val_precision: 0.5897 - val_recall: 0.5750 - val_auc: 0.7235\nEpoch 39/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.0448 - accuracy: 0.9912 - precision: 0.9893 - recall: 0.9858 - auc: 0.9995 - val_loss: 1.3388 - val_accuracy: 0.7241 - val_precision: 0.6111 - val_recall: 0.5500 - val_auc: 0.7424\nEpoch 40/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.0475 - accuracy: 0.9875 - precision: 0.9887 - recall: 0.9740 - auc: 0.9992 - val_loss: 1.4812 - val_accuracy: 0.7241 - val_precision: 0.6176 - val_recall: 0.5250 - val_auc: 0.7033\nEpoch 41/50\n200/200 [==============================] - 0s 2ms/step - loss: 0.0481 - accuracy: 0.9900 - precision: 0.9905 - recall: 0.9811 - auc: 0.9991 - val_loss: 1.4894 - val_accuracy: 0.6810 - val_precision: 0.5366 - val_recall: 0.5500 - val_auc: 0.7109\n","output_type":"stream"}]},{"cell_type":"code","source":"dl_model.evaluate(xtrain,ytrain)","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:44:40.505749Z","iopub.execute_input":"2022-10-12T16:44:40.506137Z","iopub.status.idle":"2022-10-12T16:44:40.621673Z","shell.execute_reply.started":"2022-10-12T16:44:40.506107Z","shell.execute_reply":"2022-10-12T16:44:40.620500Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"21/21 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 0.9877 - precision: 0.9867 - recall: 0.9781 - auc: 0.9992\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"[0.04649108648300171,\n 0.987730085849762,\n 0.9867256879806519,\n 0.9780701994895935,\n 0.9991880059242249]"},"metadata":{}}]},{"cell_type":"code","source":"dl_model.evaluate(xtest,ytest)","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:44:43.624512Z","iopub.execute_input":"2022-10-12T16:44:43.625803Z","iopub.status.idle":"2022-10-12T16:44:43.712987Z","shell.execute_reply.started":"2022-10-12T16:44:43.625758Z","shell.execute_reply":"2022-10-12T16:44:43.711601Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"4/4 [==============================] - 0s 3ms/step - loss: 1.4894 - accuracy: 0.6810 - precision: 0.5366 - recall: 0.5500 - auc: 0.7109\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"[1.4893760681152344,\n 0.681034505367279,\n 0.5365853905677795,\n 0.550000011920929,\n 0.7108553051948547]"},"metadata":{}}]},{"cell_type":"markdown","source":"As you can see, the ANN produced 68% test accuracy which is way less than SVM. Hence we can say that the ML algorithm produced well than that of DL algorithm. Can we stop with this conclusion or are we missing something??","metadata":{}},{"cell_type":"code","source":"print(data['Outcome'].value_counts())\ndf_class_0 = data[data['Outcome'] == 0]\ndf_class_1 = data[data['Outcome'] == 1]","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:54:48.032257Z","iopub.execute_input":"2022-10-12T16:54:48.032693Z","iopub.status.idle":"2022-10-12T16:54:48.045051Z","shell.execute_reply.started":"2022-10-12T16:54:48.032647Z","shell.execute_reply":"2022-10-12T16:54:48.043521Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"0    500\n1    268\nName: Outcome, dtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"As you can see, there is class imbalance, the amount of diabetes negative is twice than that of diabetes positive. In this scenario, we cant compare the performance of algorithms based on accuracy. So to overcome the class imbalance I oversampled the minority class to the samples of majority class (500). So the total data consits of 1000 samples with equal distribution. I repeated this process for the standardised and normalized datasets.","metadata":{}},{"cell_type":"code","source":"print(data_norm['Outcome'].value_counts())\ndf_n_class_0 = data_norm[data_norm['Outcome'] == 0]\ndf_n_class_1 = data_norm[data_norm['Outcome'] == 1]","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:55:10.374292Z","iopub.execute_input":"2022-10-12T16:55:10.375013Z","iopub.status.idle":"2022-10-12T16:55:10.384473Z","shell.execute_reply.started":"2022-10-12T16:55:10.374968Z","shell.execute_reply":"2022-10-12T16:55:10.383253Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"0.0    500\n1.0    268\nName: Outcome, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"df_class_1_over = df_class_1.sample(500, replace=True)\ndf_test_over = pd.concat([df_class_0, df_class_1_over], axis=0)\ndf_test_over.info()","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:55:25.101522Z","iopub.execute_input":"2022-10-12T16:55:25.101971Z","iopub.status.idle":"2022-10-12T16:55:25.119139Z","shell.execute_reply.started":"2022-10-12T16:55:25.101934Z","shell.execute_reply":"2022-10-12T16:55:25.117839Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 1000 entries, 1 to 397\nData columns (total 9 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   Pregnancies               1000 non-null   float64\n 1   Glucose                   1000 non-null   float64\n 2   BloodPressure             1000 non-null   float64\n 3   SkinThickness             1000 non-null   float64\n 4   Insulin                   1000 non-null   float64\n 5   BMI                       1000 non-null   float64\n 6   DiabetesPedigreeFunction  1000 non-null   float64\n 7   Age                       1000 non-null   float64\n 8   Outcome                   1000 non-null   float64\ndtypes: float64(9)\nmemory usage: 78.1 KB\n","output_type":"stream"}]},{"cell_type":"code","source":"df_n_class_1_over = df_n_class_1.sample(500, replace=True)\ndf_test_n_over = pd.concat([df_n_class_0, df_n_class_1_over], axis=0)\ndf_test_n_over.info()","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:57:07.064420Z","iopub.execute_input":"2022-10-12T16:57:07.064873Z","iopub.status.idle":"2022-10-12T16:57:07.080349Z","shell.execute_reply.started":"2022-10-12T16:57:07.064837Z","shell.execute_reply":"2022-10-12T16:57:07.079000Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 1000 entries, 1 to 740\nData columns (total 9 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   Pregnancies               1000 non-null   float64\n 1   Glucose                   1000 non-null   float64\n 2   BloodPressure             1000 non-null   float64\n 3   SkinThickness             1000 non-null   float64\n 4   Insulin                   1000 non-null   float64\n 5   BMI                       1000 non-null   float64\n 6   DiabetesPedigreeFunction  1000 non-null   float64\n 7   Age                       1000 non-null   float64\n 8   Outcome                   1000 non-null   float64\ndtypes: float64(9)\nmemory usage: 78.1 KB\n","output_type":"stream"}]},{"cell_type":"code","source":"y1=df_test_over['Outcome']\ndf_test_over=df_test_over.drop(['Outcome'],axis=1)\nX1=df_test_over","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:57:36.614762Z","iopub.execute_input":"2022-10-12T16:57:36.616182Z","iopub.status.idle":"2022-10-12T16:57:36.622762Z","shell.execute_reply.started":"2022-10-12T16:57:36.616129Z","shell.execute_reply":"2022-10-12T16:57:36.621682Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"y1n=df_test_n_over['Outcome']\ndf_test_n_over=df_test_n_over.drop(['Outcome'],axis=1)\nX1n=df_test_n_over","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:59:07.283770Z","iopub.execute_input":"2022-10-12T16:59:07.284385Z","iopub.status.idle":"2022-10-12T16:59:07.290746Z","shell.execute_reply.started":"2022-10-12T16:59:07.284352Z","shell.execute_reply":"2022-10-12T16:59:07.289416Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"The rest of the parameters are the same. This includes the train test split ratio and the algorithm parameters. Now the SVM and ANN are trained using the upsampled datasets. The same as before, normalized dataset for SVM and standardized dataset for ANN. ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX1_s_train,X1_s_test ,y1_s_train, y1_s_test = train_test_split(X1,y1,\n                                                   test_size=0.2,\n                                                   random_state=0,\n                                                  shuffle = True,\n                                                  stratify = y1)\n\nprint('training data shape is :{}.'.format(X1_s_train.shape))\nprint('training label shape is :{}.'.format(y1_s_train.shape))\nprint('testing data shape is :{}.'.format(X1_s_test.shape))\nprint('testing label shape is :{}.'.format(y1_s_test.shape))","metadata":{"execution":{"iopub.status.busy":"2022-10-12T16:59:49.564834Z","iopub.execute_input":"2022-10-12T16:59:49.565228Z","iopub.status.idle":"2022-10-12T16:59:49.578097Z","shell.execute_reply.started":"2022-10-12T16:59:49.565189Z","shell.execute_reply":"2022-10-12T16:59:49.576592Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"training data shape is :(800, 8).\ntraining label shape is :(800,).\ntesting data shape is :(200, 8).\ntesting label shape is :(200,).\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX1_s_n_train,X1_s_n_test ,y1_s_n_train, y1_s_n_test = train_test_split(X1n,y1n,\n                                                   test_size=0.2,\n                                                   random_state=0,\n                                                  shuffle = True,\n                                                  stratify = y1n)\n\nprint('training data shape is :{}.'.format(X1_s_n_train.shape))\nprint('training label shape is :{}.'.format(y1_s_n_train.shape))\nprint('testing data shape is :{}.'.format(X1_s_n_test.shape))\nprint('testing label shape is :{}.'.format(y1_s_n_test.shape))","metadata":{"execution":{"iopub.status.busy":"2022-10-12T17:01:42.414189Z","iopub.execute_input":"2022-10-12T17:01:42.414647Z","iopub.status.idle":"2022-10-12T17:01:42.426097Z","shell.execute_reply.started":"2022-10-12T17:01:42.414590Z","shell.execute_reply":"2022-10-12T17:01:42.424705Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"training data shape is :(800, 8).\ntraining label shape is :(800,).\ntesting data shape is :(200, 8).\ntesting label shape is :(200,).\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.svm import SVC\nsvc_s_model = SVC(kernel='rbf',gamma=8)\nsvc_s_model.fit(X1_s_n_train, y1_s_n_train)","metadata":{"execution":{"iopub.status.busy":"2022-10-12T17:04:28.062810Z","iopub.execute_input":"2022-10-12T17:04:28.063254Z","iopub.status.idle":"2022-10-12T17:04:28.100126Z","shell.execute_reply.started":"2022-10-12T17:04:28.063217Z","shell.execute_reply":"2022-10-12T17:04:28.098945Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"SVC(gamma=8)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\npredictions= svc_s_model.predict(X1_s_n_train)\npercentage=svc_s_model.score(X1_s_n_train,y1_s_n_train)\nres=confusion_matrix(y1_s_n_train,predictions)\nprint(\"Training confusion matrix\")\nprint(res)\npredictions= svc_s_model.predict(X1_s_n_test)\npercentage=svc_s_model.score(X1_s_n_test,y1_s_n_test)\nres=confusion_matrix(y1_s_n_test,predictions)\nprint(\"validation confusion matrix\")\nprint(res)\nprint(classification_report(y1_s_n_test, predictions))\n# check the accuracy on the training set\nprint('training accuracy = '+str(svc_s_model.score(X1_s_n_train, y1_s_n_train)*100))\nprint('testing accuracy = '+str(svc_s_model.score(X1_s_n_test, y1_s_n_test)*100))","metadata":{"execution":{"iopub.status.busy":"2022-10-12T17:08:36.071465Z","iopub.execute_input":"2022-10-12T17:08:36.071905Z","iopub.status.idle":"2022-10-12T17:08:36.187310Z","shell.execute_reply.started":"2022-10-12T17:08:36.071870Z","shell.execute_reply":"2022-10-12T17:08:36.186131Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Training confusion matrix\n[[342  58]\n [ 73 327]]\nvalidation confusion matrix\n[[83 17]\n [16 84]]\n              precision    recall  f1-score   support\n\n         0.0       0.84      0.83      0.83       100\n         1.0       0.83      0.84      0.84       100\n\n    accuracy                           0.83       200\n   macro avg       0.84      0.83      0.83       200\nweighted avg       0.84      0.83      0.83       200\n\ntraining accuracy = 83.625\ntesting accuracy = 83.5\n","output_type":"stream"}]},{"cell_type":"markdown","source":"There isn't much change in the accuracy of the algorithm but there is huge improvement in the classification report before and after sampling, especially for the diabetes class. ","metadata":{}},{"cell_type":"code","source":"num_epochs = 50\nhistory = dl_model.fit(X1_s_train ,\n                    y1_s_train ,\n                    epochs= num_epochs ,\n                    steps_per_epoch=200,\n                    validation_data=(X1_s_test ,y1_s_test))","metadata":{"execution":{"iopub.status.busy":"2022-10-12T17:09:41.462511Z","iopub.execute_input":"2022-10-12T17:09:41.462947Z","iopub.status.idle":"2022-10-12T17:10:14.629710Z","shell.execute_reply.started":"2022-10-12T17:09:41.462912Z","shell.execute_reply":"2022-10-12T17:10:14.628478Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Epoch 1/50\n200/200 [==============================] - 2s 7ms/step - loss: 0.5752 - accuracy: 0.7063 - precision: 0.7017 - recall: 0.7175 - auc: 0.7778 - val_loss: 0.4512 - val_accuracy: 0.7650 - val_precision: 0.8193 - val_recall: 0.6800 - val_auc: 0.8728\nEpoch 2/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.4832 - accuracy: 0.7650 - precision: 0.7650 - recall: 0.7650 - auc: 0.8487 - val_loss: 0.4714 - val_accuracy: 0.7600 - val_precision: 0.8939 - val_recall: 0.5900 - val_auc: 0.8872\nEpoch 3/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.4665 - accuracy: 0.7837 - precision: 0.7816 - recall: 0.7875 - auc: 0.8590 - val_loss: 0.4259 - val_accuracy: 0.8050 - val_precision: 0.7521 - val_recall: 0.9100 - val_auc: 0.9034\nEpoch 4/50\n200/200 [==============================] - 1s 4ms/step - loss: 0.4427 - accuracy: 0.7937 - precision: 0.7887 - recall: 0.8025 - auc: 0.8743 - val_loss: 0.3999 - val_accuracy: 0.8050 - val_precision: 0.8427 - val_recall: 0.7500 - val_auc: 0.9056\nEpoch 5/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.4236 - accuracy: 0.8025 - precision: 0.8010 - recall: 0.8050 - auc: 0.8855 - val_loss: 0.4019 - val_accuracy: 0.8150 - val_precision: 0.8462 - val_recall: 0.7700 - val_auc: 0.9024\nEpoch 6/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.4261 - accuracy: 0.8025 - precision: 0.8040 - recall: 0.8000 - auc: 0.8848 - val_loss: 0.4147 - val_accuracy: 0.7800 - val_precision: 0.8684 - val_recall: 0.6600 - val_auc: 0.9034\nEpoch 7/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.4259 - accuracy: 0.8000 - precision: 0.7970 - recall: 0.8050 - auc: 0.8844 - val_loss: 0.3836 - val_accuracy: 0.8500 - val_precision: 0.8500 - val_recall: 0.8500 - val_auc: 0.9119\nEpoch 8/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.4252 - accuracy: 0.8025 - precision: 0.7995 - recall: 0.8075 - auc: 0.8847 - val_loss: 0.3921 - val_accuracy: 0.8300 - val_precision: 0.7845 - val_recall: 0.9100 - val_auc: 0.9110\nEpoch 9/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.4127 - accuracy: 0.8100 - precision: 0.8010 - recall: 0.8250 - auc: 0.8920 - val_loss: 0.5545 - val_accuracy: 0.7300 - val_precision: 0.9259 - val_recall: 0.5000 - val_auc: 0.9063\nEpoch 10/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.4041 - accuracy: 0.8125 - precision: 0.8173 - recall: 0.8050 - auc: 0.8971 - val_loss: 0.3932 - val_accuracy: 0.8200 - val_precision: 0.8902 - val_recall: 0.7300 - val_auc: 0.9113\nEpoch 11/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.3912 - accuracy: 0.8275 - precision: 0.8243 - recall: 0.8325 - auc: 0.9036 - val_loss: 0.3919 - val_accuracy: 0.8450 - val_precision: 0.8632 - val_recall: 0.8200 - val_auc: 0.9046\nEpoch 12/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.3891 - accuracy: 0.8175 - precision: 0.8159 - recall: 0.8200 - auc: 0.9057 - val_loss: 0.3812 - val_accuracy: 0.8200 - val_precision: 0.8265 - val_recall: 0.8100 - val_auc: 0.9106\nEpoch 13/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.3882 - accuracy: 0.8213 - precision: 0.8237 - recall: 0.8175 - auc: 0.9049 - val_loss: 0.3990 - val_accuracy: 0.8250 - val_precision: 0.9012 - val_recall: 0.7300 - val_auc: 0.9097\nEpoch 14/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.3764 - accuracy: 0.8338 - precision: 0.8329 - recall: 0.8350 - auc: 0.9106 - val_loss: 0.3657 - val_accuracy: 0.8350 - val_precision: 0.8681 - val_recall: 0.7900 - val_auc: 0.9189\nEpoch 15/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.3698 - accuracy: 0.8400 - precision: 0.8452 - recall: 0.8325 - auc: 0.9159 - val_loss: 0.3613 - val_accuracy: 0.8350 - val_precision: 0.8681 - val_recall: 0.7900 - val_auc: 0.9212\nEpoch 16/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.3654 - accuracy: 0.8288 - precision: 0.8312 - recall: 0.8250 - auc: 0.9170 - val_loss: 0.3759 - val_accuracy: 0.8400 - val_precision: 0.8542 - val_recall: 0.8200 - val_auc: 0.9132\nEpoch 17/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.3807 - accuracy: 0.8250 - precision: 0.8218 - recall: 0.8300 - auc: 0.9081 - val_loss: 0.3559 - val_accuracy: 0.8500 - val_precision: 0.8302 - val_recall: 0.8800 - val_auc: 0.9224\nEpoch 18/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.3641 - accuracy: 0.8400 - precision: 0.8350 - recall: 0.8475 - auc: 0.9183 - val_loss: 0.3542 - val_accuracy: 0.8500 - val_precision: 0.8977 - val_recall: 0.7900 - val_auc: 0.9266\nEpoch 19/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.3574 - accuracy: 0.8388 - precision: 0.8362 - recall: 0.8425 - auc: 0.9210 - val_loss: 0.3666 - val_accuracy: 0.8350 - val_precision: 0.8526 - val_recall: 0.8100 - val_auc: 0.9182\nEpoch 20/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.3537 - accuracy: 0.8400 - precision: 0.8350 - recall: 0.8475 - auc: 0.9234 - val_loss: 0.3634 - val_accuracy: 0.8350 - val_precision: 0.8681 - val_recall: 0.7900 - val_auc: 0.9178\nEpoch 21/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.3376 - accuracy: 0.8450 - precision: 0.8538 - recall: 0.8325 - auc: 0.9307 - val_loss: 0.3753 - val_accuracy: 0.8500 - val_precision: 0.8182 - val_recall: 0.9000 - val_auc: 0.9196\nEpoch 22/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.3309 - accuracy: 0.8587 - precision: 0.8491 - recall: 0.8725 - auc: 0.9340 - val_loss: 0.3553 - val_accuracy: 0.8200 - val_precision: 0.8810 - val_recall: 0.7400 - val_auc: 0.9269\nEpoch 23/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.3249 - accuracy: 0.8562 - precision: 0.8608 - recall: 0.8500 - auc: 0.9365 - val_loss: 0.3985 - val_accuracy: 0.8150 - val_precision: 0.8987 - val_recall: 0.7100 - val_auc: 0.9191\nEpoch 24/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.3232 - accuracy: 0.8500 - precision: 0.8483 - recall: 0.8525 - auc: 0.9362 - val_loss: 0.3898 - val_accuracy: 0.8200 - val_precision: 0.7623 - val_recall: 0.9300 - val_auc: 0.9266\nEpoch 25/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.3144 - accuracy: 0.8487 - precision: 0.8462 - recall: 0.8525 - auc: 0.9408 - val_loss: 0.3891 - val_accuracy: 0.8100 - val_precision: 0.8974 - val_recall: 0.7000 - val_auc: 0.9216\nEpoch 26/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.3186 - accuracy: 0.8600 - precision: 0.8655 - recall: 0.8525 - auc: 0.9385 - val_loss: 0.3415 - val_accuracy: 0.8450 - val_precision: 0.8165 - val_recall: 0.8900 - val_auc: 0.9330\nEpoch 27/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.3102 - accuracy: 0.8587 - precision: 0.8670 - recall: 0.8475 - auc: 0.9421 - val_loss: 0.3366 - val_accuracy: 0.8550 - val_precision: 0.8381 - val_recall: 0.8800 - val_auc: 0.9312\nEpoch 28/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.3004 - accuracy: 0.8725 - precision: 0.8782 - recall: 0.8650 - auc: 0.9468 - val_loss: 0.3280 - val_accuracy: 0.8550 - val_precision: 0.8817 - val_recall: 0.8200 - val_auc: 0.9372\nEpoch 29/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.2930 - accuracy: 0.8687 - precision: 0.8697 - recall: 0.8675 - auc: 0.9500 - val_loss: 0.3667 - val_accuracy: 0.8350 - val_precision: 0.7965 - val_recall: 0.9000 - val_auc: 0.9255\nEpoch 30/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.2889 - accuracy: 0.8838 - precision: 0.8790 - recall: 0.8900 - auc: 0.9509 - val_loss: 0.3353 - val_accuracy: 0.8500 - val_precision: 0.8431 - val_recall: 0.8600 - val_auc: 0.9322\nEpoch 31/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.2923 - accuracy: 0.8725 - precision: 0.8744 - recall: 0.8700 - auc: 0.9490 - val_loss: 0.3303 - val_accuracy: 0.8500 - val_precision: 0.8804 - val_recall: 0.8100 - val_auc: 0.9362\nEpoch 32/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.2842 - accuracy: 0.8737 - precision: 0.8766 - recall: 0.8700 - auc: 0.9520 - val_loss: 0.3536 - val_accuracy: 0.8450 - val_precision: 0.8791 - val_recall: 0.8000 - val_auc: 0.9334\nEpoch 33/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.2788 - accuracy: 0.8863 - precision: 0.8892 - recall: 0.8825 - auc: 0.9547 - val_loss: 0.3326 - val_accuracy: 0.8450 - val_precision: 0.8876 - val_recall: 0.7900 - val_auc: 0.9364\nEpoch 34/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.2721 - accuracy: 0.8925 - precision: 0.8985 - recall: 0.8850 - auc: 0.9568 - val_loss: 0.3194 - val_accuracy: 0.8700 - val_precision: 0.8627 - val_recall: 0.8800 - val_auc: 0.9379\nEpoch 35/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.2668 - accuracy: 0.8863 - precision: 0.8872 - recall: 0.8850 - auc: 0.9593 - val_loss: 0.3702 - val_accuracy: 0.8150 - val_precision: 0.9200 - val_recall: 0.6900 - val_auc: 0.9388\nEpoch 36/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.2688 - accuracy: 0.8763 - precision: 0.8772 - recall: 0.8750 - auc: 0.9575 - val_loss: 0.3519 - val_accuracy: 0.8300 - val_precision: 0.9125 - val_recall: 0.7300 - val_auc: 0.9369\nEpoch 37/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.2516 - accuracy: 0.8988 - precision: 0.8997 - recall: 0.8975 - auc: 0.9641 - val_loss: 0.3205 - val_accuracy: 0.8550 - val_precision: 0.9176 - val_recall: 0.7800 - val_auc: 0.9436\nEpoch 38/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.2388 - accuracy: 0.9100 - precision: 0.9121 - recall: 0.9075 - auc: 0.9689 - val_loss: 0.3100 - val_accuracy: 0.8500 - val_precision: 0.8804 - val_recall: 0.8100 - val_auc: 0.9428\nEpoch 39/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.2418 - accuracy: 0.9013 - precision: 0.9063 - recall: 0.8950 - auc: 0.9666 - val_loss: 0.3231 - val_accuracy: 0.8650 - val_precision: 0.9011 - val_recall: 0.8200 - val_auc: 0.9410\nEpoch 40/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.2358 - accuracy: 0.9062 - precision: 0.9114 - recall: 0.9000 - auc: 0.9684 - val_loss: 0.3211 - val_accuracy: 0.8350 - val_precision: 0.8851 - val_recall: 0.7700 - val_auc: 0.9412\nEpoch 41/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.2428 - accuracy: 0.8988 - precision: 0.8997 - recall: 0.8975 - auc: 0.9665 - val_loss: 0.3202 - val_accuracy: 0.8100 - val_precision: 0.8605 - val_recall: 0.7400 - val_auc: 0.9435\nEpoch 42/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.2226 - accuracy: 0.9125 - precision: 0.9188 - recall: 0.9050 - auc: 0.9727 - val_loss: 0.3533 - val_accuracy: 0.8750 - val_precision: 0.8319 - val_recall: 0.9400 - val_auc: 0.9397\nEpoch 43/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.2221 - accuracy: 0.8950 - precision: 0.9031 - recall: 0.8850 - auc: 0.9725 - val_loss: 0.3144 - val_accuracy: 0.8800 - val_precision: 0.8519 - val_recall: 0.9200 - val_auc: 0.9450\nEpoch 44/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.2187 - accuracy: 0.8963 - precision: 0.9013 - recall: 0.8900 - auc: 0.9744 - val_loss: 0.3075 - val_accuracy: 0.8650 - val_precision: 0.8476 - val_recall: 0.8900 - val_auc: 0.9432\nEpoch 45/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.2046 - accuracy: 0.9200 - precision: 0.9308 - recall: 0.9075 - auc: 0.9781 - val_loss: 0.3152 - val_accuracy: 0.8550 - val_precision: 0.8817 - val_recall: 0.8200 - val_auc: 0.9412\nEpoch 46/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.2017 - accuracy: 0.9200 - precision: 0.9308 - recall: 0.9075 - auc: 0.9778 - val_loss: 0.3107 - val_accuracy: 0.8450 - val_precision: 0.8632 - val_recall: 0.8200 - val_auc: 0.9419\nEpoch 47/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.2045 - accuracy: 0.9200 - precision: 0.9221 - recall: 0.9175 - auc: 0.9770 - val_loss: 0.3689 - val_accuracy: 0.8400 - val_precision: 0.9250 - val_recall: 0.7400 - val_auc: 0.9353\nEpoch 48/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.1877 - accuracy: 0.9275 - precision: 0.9362 - recall: 0.9175 - auc: 0.9821 - val_loss: 0.3141 - val_accuracy: 0.8600 - val_precision: 0.8913 - val_recall: 0.8200 - val_auc: 0.9449\nEpoch 49/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.1854 - accuracy: 0.9337 - precision: 0.9415 - recall: 0.9250 - auc: 0.9830 - val_loss: 0.3128 - val_accuracy: 0.8850 - val_precision: 0.9053 - val_recall: 0.8600 - val_auc: 0.9415\nEpoch 50/50\n200/200 [==============================] - 1s 3ms/step - loss: 0.1859 - accuracy: 0.9300 - precision: 0.9388 - recall: 0.9200 - auc: 0.9811 - val_loss: 0.3797 - val_accuracy: 0.8750 - val_precision: 0.8319 - val_recall: 0.9400 - val_auc: 0.9362\n","output_type":"stream"}]},{"cell_type":"code","source":"dl_model.evaluate(X1_s_train ,\n                    y1_s_train)","metadata":{"execution":{"iopub.status.busy":"2022-10-12T17:13:30.425995Z","iopub.execute_input":"2022-10-12T17:13:30.426409Z","iopub.status.idle":"2022-10-12T17:13:30.558684Z","shell.execute_reply.started":"2022-10-12T17:13:30.426372Z","shell.execute_reply":"2022-10-12T17:13:30.557685Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"25/25 [==============================] - 0s 2ms/step - loss: 0.2244 - accuracy: 0.9025 - precision: 0.8440 - recall: 0.9875 - auc: 0.9864\n","output_type":"stream"},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"[0.2244451344013214,\n 0.9024999737739563,\n 0.8440170884132385,\n 0.987500011920929,\n 0.9863780736923218]"},"metadata":{}}]},{"cell_type":"code","source":"dl_model.evaluate(X1_s_test ,y1_s_test)","metadata":{"execution":{"iopub.status.busy":"2022-10-12T17:13:47.072733Z","iopub.execute_input":"2022-10-12T17:13:47.073706Z","iopub.status.idle":"2022-10-12T17:13:47.173604Z","shell.execute_reply.started":"2022-10-12T17:13:47.073667Z","shell.execute_reply":"2022-10-12T17:13:47.172448Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"7/7 [==============================] - 0s 3ms/step - loss: 0.3797 - accuracy: 0.8750 - precision: 0.8319 - recall: 0.9400 - auc: 0.9362\n","output_type":"stream"},{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"[0.3796664774417877,\n 0.875,\n 0.8318583965301514,\n 0.9399999976158142,\n 0.9362000823020935]"},"metadata":{}}]},{"cell_type":"markdown","source":"The ANN trained on the standardised and upsampled data performed the best result with 88% test accuracy. I have done a lot of work in this notebook, hope this deserves an upvote!! Thanks...\nPlease do mention if I have done something wrong.","metadata":{}}]}